{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV45NgMto8fH"
      },
      "outputs": [],
      "source": [
        "conda create -n ai python=3.11 -y && conda activate ai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch\n",
        "pip install git+https://github.com/huggingface/transformers\n",
        "pip install git+https://github.com/huggingface/accelerate\n",
        "pip install huggingface_hub"
      ],
      "metadata": {
        "id": "qnOIEXg0pHmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from huggingface_hub import login\n",
        "login(token=\"Your Token\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"fdtn-ai/Foundation-Sec-8B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"fdtn-ai/Foundation-Sec-8B\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "S2nLlVyHpJvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alert = {\n",
        "    \"src_ip\": \"192.168.10.12\",\n",
        "    \"dst_ip\": \"10.0.0.5\",\n",
        "    \"src_port\": 554,\n",
        "    \"dst_port\": 443,\n",
        "    \"protocol\": \"TCP\",\n",
        "    \"payload\": \"GET /admin/config.php?cmd=rm -rf / HTTP/1.1\"\n",
        "}\n",
        "\n",
        "# Prompt for MITRE ATT&CK mapping\n",
        "prompt = f\"\"\"\n",
        "You are a cybersecurity analyst. Given the following network alert, map it to MITRE ATT&CK techniques.\n",
        "\n",
        "Alert:\n",
        "- Source IP: {alert['src_ip']}\n",
        "- Destination IP: {alert['dst_ip']}\n",
        "- Source Port: {alert['src_port']}\n",
        "- Destination Port: {alert['dst_port']}\n",
        "- Protocol: {alert['protocol']}\n",
        "- Payload: {alert['payload']}\n",
        "\n",
        "Which MITRE ATT&CK techniques does this alert match? Return the technique name and ID.\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(\n",
        "    prompt,\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    add_special_tokens=True\n",
        ")\n",
        "\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "pad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
        "outputs = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"],\n",
        "    max_new_tokens=550,\n",
        "    do_sample=True,\n",
        "    temperature=0.1,\n",
        "    top_p=0.9,\n",
        "    pad_token_id=pad_token_id\n",
        ")\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "response = response.replace(prompt, \"\").strip()\n",
        "print(response)"
      ],
      "metadata": {
        "id": "GdJfB-hnpOCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_scenario = {\n",
        "    \"target\": \"e-commerce web server running WordPress\",\n",
        "    \"entry_point\": \"exposed admin interface\",\n",
        "    \"constraints\": \"avoid detection, maintain persistence\"\n",
        "}\n",
        "\n",
        "# Construct prompt\n",
        "prompt = f\"\"\"Simulate a realistic cyber attack sequence based on these parameters:\n",
        "Target: {attack_scenario['target']}\n",
        "Initial Access: {attack_scenario['entry_point']}\n",
        "Constraints: {attack_scenario['constraints']}\n",
        "\n",
        "Generate attack steps in MITRE ATT&CK order:\n",
        "1. Reconnaissance:\"\"\"\n",
        "\n",
        "# Generate simulation\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(\n",
        "    inputs.input_ids,\n",
        "    max_new_tokens=400,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    do_sample=True,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Decode and print\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(response.split(\"Generate attack steps\")[0])  # Remove original promp"
      ],
      "metadata": {
        "id": "2gyqvfzxpedf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct prompt\n",
        "prompt = f\"\"\"Simulate lateral movement using Pass-the-Hash after obtaining credentials from a Windows workstation. Include steps to exploit SMB vulnerabilities.\"\"\"\n",
        "\n",
        "# Generate simulation\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(\n",
        "    inputs.input_ids,\n",
        "    max_new_tokens=400,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    do_sample=True,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Decode and print\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "# print(response.split(\"Generate attack steps\")[0])  # Remove original prompt\n",
        "print(response)"
      ],
      "metadata": {
        "id": "uvRLtds4pgor"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}